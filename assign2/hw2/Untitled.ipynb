{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c40aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import submission\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "01bf1b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== START GRADING\n",
      "----- START PART 1a-1-hidden: \n",
      "----- END PART 1a-1-hidden [took 0:00:00 (max allowed 1 seconds), ???/2 points (hidden test ungraded)]\n",
      "\n",
      "----- START PART 2a-0-basic: basic test\n",
      "----- END PART 2a-0-basic [took 0:00:00 (max allowed 1 seconds), 1/1 points]\n",
      "\n",
      "----- START PART 2a-1-hidden: test multiple instances of the same word in a sentence\n",
      "----- END PART 2a-1-hidden [took 0:00:00.000999 (max allowed 1 seconds), ???/1 points (hidden test ungraded)]\n",
      "\n",
      "----- START PART 2b-0-basic: basic sanity check for learning correct weights on two training and testing examples each\n",
      "----- END PART 2b-0-basic [took 0:00:00 (max allowed 1 seconds), 1/1 points]\n",
      "\n",
      "----- START PART 2b-1-basic: test correct overriding of positive weight due to one negative instance with repeated words\n",
      "----- END PART 2b-1-basic [took 0:00:00 (max allowed 1 seconds), 1/1 points]\n",
      "\n",
      "----- START PART 2b-2-basic: test classifier on real polarity dev dataset\n",
      "Read 3554 examples from polarity.train\n",
      "Read 3554 examples from polarity.dev\n",
      "11626 weights\n",
      "Official: train error = 0.07400112549240292, dev error = 0.2771525042205965\n",
      "----- END PART 2b-2-basic [took 0:00:01.186269 (max allowed 8 seconds), 6/6 points]\n",
      "\n",
      "----- START PART 2c-0-basic: test basic ngram features\n",
      "----- END PART 2c-0-basic [took 0:00:00 (max allowed 1 seconds), 1/1 points]\n",
      "\n",
      "----- START PART 2c-1-hidden: test feature extraction on random sentence and random length\n",
      "----- END PART 2c-1-hidden [took 0:00:00.001037 (max allowed 1 seconds), ???/2 points (hidden test ungraded)]\n",
      "\n",
      "----- START PART 3a-1-hidden: \n",
      "----- END PART 3a-1-hidden [took 0:00:00 (max allowed 1 seconds), ???/1 points (hidden test ungraded)]\n",
      "\n",
      "----- START PART 3a-2-hidden: \n",
      "----- END PART 3a-2-hidden [took 0:00:00 (max allowed 1 seconds), ???/1 points (hidden test ungraded)]\n",
      "\n",
      "----- START PART 3b-0-basic: test basic k-means on hardcoded datapoints\n",
      "----- END PART 3b-0-basic [took 0:00:00 (max allowed 1 seconds), 1/1 points]\n",
      "\n",
      "----- START PART 3b-1-hidden: \n",
      "----- END PART 3b-1-hidden [took 0:00:00.124992 (max allowed 3 seconds), ???/1 points (hidden test ungraded)]\n",
      "\n",
      "----- START PART 3b-2-hidden: \n",
      "----- END PART 3b-2-hidden [took 0:00:00.126029 (max allowed 3 seconds), ???/2 points (hidden test ungraded)]\n",
      "\n",
      "----- START PART 3b-3-hidden: make sure the code runs fast enough\n",
      "----- END PART 3b-3-hidden [took 0:00:01.226277 (max allowed 4 seconds), ???/1 points (hidden test ungraded)]\n",
      "\n",
      "----- START PART 3b-4-hidden: make sure the code runs fast enough\n",
      "----- END PART 3b-4-hidden [took 0:00:01.211274 (max allowed 4 seconds), ???/1 points (hidden test ungraded)]\n",
      "\n",
      "Note that the hidden test cases do not check for correctness.\n",
      "They are provided for you to verify that the functions do not crash and run within the time limit.\n",
      "Points for these parts not assigned by the grader (indicated by \"--\").\n",
      "========== END GRADING [11 points (11/11 points (auto/coding only) + 0/0 extra credit)]\n",
      "Wrote results to grader-auto.out\n",
      "Total max points (basic auto/coding + hidden auto/coding + manual/written): 11 + 12 + 0 = 23\n"
     ]
    }
   ],
   "source": [
    "!python grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "cd891575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== START GRADING\n",
      "----- START PART 3a-2-hidden: \n",
      "----- END PART 3a-2-hidden [took 0:00:00 (max allowed 1 seconds), ???/1 points (hidden test ungraded)]\n",
      "\n",
      "Note that the hidden test cases do not check for correctness.\n",
      "They are provided for you to verify that the functions do not crash and run within the time limit.\n",
      "Points for these parts not assigned by the grader (indicated by \"--\").\n",
      "========== END GRADING [0 points (0/0 points (auto/coding only) + 0/0 extra credit)]\n",
      "Wrote results to grader-auto.out\n",
      "Total max points (basic auto/coding + hidden auto/coding + manual/written): 0 + 1 + 0 = 1\n"
     ]
    }
   ],
   "source": [
    "!python grader.py 3a-2-hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30502d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "dic = defaultdict(int)\n",
    "\n",
    "dic['dd'] = dic['dd'] + 1\n",
    "dic['dd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "131a7cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWordFeatures(x):\n",
    "    \"\"\"\n",
    "    Extract word features for a string x. Words are delimited by\n",
    "    whitespace characters only.\n",
    "    @param string x: \n",
    "    @return dict: feature vector representation of x.\n",
    "    Example: \"I am what I am\" --> {'I': 2, 'am': 2, 'what': 1}\n",
    "    \"\"\"\n",
    "    # BEGIN_YOUR_ANSWER (our solution is 6 lines of code, but don't worry if you deviate from this)\n",
    "    word_list = x.split(' ')\n",
    "    word_dict = {}\n",
    "    for word in word_list:\n",
    "        if word in word_dict:\n",
    "            word_dict[word] = word_dict[word] + 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "    \n",
    "    return word_dict\n",
    "    # END_YOUR_ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c76f487c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26900\\2840591828.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# BEGIN_YOUR_ANSWER (our solution is 14 lines of code, but don't worry if you deviate from this)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadExamples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainExamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumIters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\source\\repos\\AI(CSED342)\\assign 2\\hw2\\util.py\u001b[0m in \u001b[0;36mreadExamples\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m     '''\n\u001b[0;32m     30\u001b[0m     \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"ISO-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[1;31m# Format of each line: <output label (+1 or -1)> <input sentence>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not tuple"
     ]
    }
   ],
   "source": [
    "weights = {}  # feature => weight\n",
    "\n",
    "def sigmoid(n):\n",
    "    return 1 / (1 + math.exp(-n))\n",
    "\n",
    "# BEGIN_YOUR_ANSWER (our solution is 14 lines of code, but don't worry if you deviate from this)\n",
    "train_set = readExamples(trainExamples)\n",
    "for _ in range(numIters):\n",
    "    for (x, y) in train_set:\n",
    "        feature = featureExtractor(x)\n",
    "        if (y==1):\n",
    "            util.increment(weights, eta*(1-sigmoid(util.dotProduct(weights, feature))), feature)\n",
    "        elif (y==-1):\n",
    "            util.increment(weights, -eta*sigmoid(util.dotProduct(weights, feature)), feature)\n",
    "# END_YOUR_ANSWER\n",
    "return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c89b0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi bye 1\n",
      "hi hi -1\n"
     ]
    }
   ],
   "source": [
    "weights = {'hi':1, 'bye':1}\n",
    "feature = {'hi':2, 'ggg':3}\n",
    "\n",
    "increment(weights, 1, feature)\n",
    "\n",
    "trainExamples = ((\"hi bye\", 1), (\"hi hi\", -1))\n",
    "for x, y in trainExamples:\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "863e7bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I am what': 2, 'am what I': 2, 'what I am': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"I am what I am what I am\"\n",
    "n = 3\n",
    "word_list = x.split(' ')\n",
    "\n",
    "phi = {}\n",
    "for i in range(len(word_list)-n+1):\n",
    "    n_words = ' '.join(word_list[i:n+i])\n",
    "    if n_words in phi:\n",
    "        phi[n_words] += 1\n",
    "    else:\n",
    "        phi[n_words] = 1\n",
    "        \n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b495a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.5, 1.5], [3.0, 1.5]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains = [[-1,0 ], [2, 0], [0, 3], [4, 3]]\n",
    "z = [0, 1, 0, 1]\n",
    "centroid_list = [[0, 0], [0, 0]]\n",
    "centroid_count = [0, 0]\n",
    "for point, center in zip(trains, z):\n",
    "    centroid_list[center][0] += point[0]\n",
    "    centroid_list[center][1] += point[1]\n",
    "    centroid_count[center] += 1\n",
    "    \n",
    "centroid_list[0][0]/=centroid_count[0]\n",
    "centroid_list[0][1]/=centroid_count[0]\n",
    "centroid_list[1][0]/=centroid_count[1]\n",
    "centroid_list[1][1]/=centroid_count[1]\n",
    "\n",
    "centroid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bcf43283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mu_x': -1.0, 'mu_y': 0.0}, {'mu_x': 2.0, 'mu_y': 2.0}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_distance(a, b):\n",
    "    x = (a[0]-b[0])**2\n",
    "    y = (a[1]-b[1])**2\n",
    "    return x+y\n",
    "\n",
    "trains = [[-1, 0], [2, 0], [0, 3], [4, 3]]\n",
    "centroids = [[-1, -1], [2, 3]]\n",
    "\n",
    "while(True): \n",
    "    cluster = []\n",
    "    #각 값에 center값 할당\n",
    "    for point in trains:\n",
    "        distance_from_centroids = []\n",
    "        for centroid in centroids:\n",
    "            distance_from_centroids.append(get_distance(point, centroid))\n",
    "        cluster_index = distance_from_centroids.index(min(distance_from_centroids))\n",
    "        cluster.append(cluster_index)\n",
    "    \n",
    "    #cluster에 따른 centroid재설정\n",
    "    pre_centroids = centroids\n",
    "    centroids = [[0 for i in range(2)] for j in range(2)]\n",
    "    centroid_counter = [0 for i in range(2)]\n",
    "    for point, centroid in zip(trains, cluster):\n",
    "        centroids[centroid][0] += point[0]\n",
    "        centroids[centroid][1] += point[1]\n",
    "        centroid_counter[centroid] += 1\n",
    "        \n",
    "    for i in range(len(centroids)):\n",
    "        if centroid_counter[i] == 0:\n",
    "            continue\n",
    "        centroids[i][0] /= centroid_counter[i]\n",
    "        centroids[i][1] /= centroid_counter[i]\n",
    "        \n",
    "    if(pre_centroids == centroids):\n",
    "        break\n",
    "\n",
    "#결과 centroids dictionary에 담기\n",
    "result_centroids = []\n",
    "for centroid in centroids:\n",
    "    dic = {'mu_x': centroid[0], 'mu_y': centroid[1]}\n",
    "    result_centroids.append(dic)\n",
    "    \n",
    "result_centroids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "90fb20c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 0], [2, 0]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_distance(a, b):\n",
    "    x = (a[0]-b[0])**2\n",
    "    y = (a[1]-b[1])**2\n",
    "    return x+y\n",
    "\n",
    "trains = [[-1, 0], [2, 0], [0, 3], [4, 3]]\n",
    "centroids = [[-1, -1], [2, 3]]\n",
    "get_distance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c74cb4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({'plot0': 4, 'bad': 1, 'worst': 1, 'filler0': 1})]\n",
      "[Counter({'plot0': 4, 'bad': 1, 'worst': 1, 'filler0': 1}), Counter({'plot0': 3, 'bad': 2, 'plot1': 1, 'filler0': 1})]\n",
      "[Counter({'plot0': 4, 'bad': 1, 'worst': 1, 'filler0': 1}), Counter({'plot0': 3, 'bad': 2, 'plot1': 1, 'filler0': 1}), Counter({'plot1': 3, 'fantastic': 1, 'good': 1, 'plot0': 1, 'filler0': 1})]\n"
     ]
    }
   ],
   "source": [
    "print(generateClusteringExamples(1, 2, 1))\n",
    "print(generateClusteringExamples(2, 2, 1))\n",
    "print(generateClusteringExamples(3, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8531cc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: 0, 1: 4}, {0: 0, 1: 0}]\n",
      "5.5\n"
     ]
    }
   ],
   "source": [
    "def kmeans(examples, K, maxIters):\n",
    "    '''\n",
    "    examples: list of examples, each example is a string-to-double dict representing a sparse vector.\n",
    "    K: number of desired clusters. Assume that 0 < K <= |examples|.\n",
    "    maxIters: maximum number of iterations to run for (you should terminate early if the algorithm converges).\n",
    "    Return: (length K list of cluster centroids,\n",
    "            list of assignments, (i.e. if examples[i] belongs to centers[j], then assignments[i] = j)\n",
    "            final reconstruction loss)\n",
    "    '''\n",
    "    # BEGIN_YOUR_ANSWER (our solution is 40 lines of code, but don't worry if you deviate from this)\n",
    "    def get_euclidean_distance(v1, v2):\n",
    "        res = 0\n",
    "        keys = list(set(list(v1.keys()) + list(v2.keys())))\n",
    "        for key in keys:\n",
    "            res += (v1.get(key, 0) - v2.get(key, 0))**2\n",
    "        return res\n",
    "        \n",
    "    # 주어진 벡터 중 K개 랜덤하게 center 배정\n",
    "    centers = random.sample(examples, K)\n",
    "    print(centers)\n",
    "    pre_loss = 0\n",
    "    for _ in range(maxIters):\n",
    "        # 벡터를 가까운 center에 할당, L2 loss 계산\n",
    "        assignments = []\n",
    "        loss = 0\n",
    "        for example in examples:\n",
    "            distances = [get_euclidean_distance(example, center) for center in centers]\n",
    "            min_index = distances.index(min(distances))\n",
    "            assignments.append(min_index)\n",
    "            loss += distances[min_index]\n",
    "        # loss=pre_loss라면 break\n",
    "        if(loss == pre_loss):\n",
    "            break\n",
    "        # 각 center에 할당된 벡터들의 평균에 따라 center 재정의\n",
    "        pre_loss = loss\n",
    "        new_centers = []\n",
    "        for i in range(K):\n",
    "            new_center = Counter()\n",
    "            size_counter = 0\n",
    "            for j in range(len(examples)):\n",
    "                if assignments[j] != i:\n",
    "                    continue\n",
    "                new_center.update(examples[j])\n",
    "                size_counter += 1\n",
    "            new_center = {k: new_center[k]/size_counter for k in new_center.keys()}\n",
    "            new_centers.append(new_center)\n",
    "        centers = new_centers\n",
    "        \n",
    "    return centers, assignments, loss   \n",
    "\n",
    "x1 = {0:0, 1:0}\n",
    "x2 = {0:0, 1:1}\n",
    "x3 = {0:0, 1:2}\n",
    "x4 = {0:0, 1:3}\n",
    "x5 = {0:0, 1:4}\n",
    "x6 = {0:0, 1:5}\n",
    "examples = [x1, x2, x3, x4, x5, x6]\n",
    "centers, assignments, totalCost = kmeans(examples, 2, maxIters=10)\n",
    "print(totalCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfe34e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'plot0': 3, 'bad': 1, 'worst': 1, 'plot2': 1, 'filler8': 1})\n",
      "Counter({'plot0': 3, 'terrible': 1, 'bad': 1, 'plot2': 1, 'filler9': 1})\n",
      "Counter({'plot1': 2, 'awful': 1, 'terrible': 1, 'plot2': 1, 'plot0': 1, 'filler2': 1})\n",
      "Counter({'plot0': 3, 'fantastic': 2, 'plot1': 1, 'filler6': 1})\n",
      "Counter({'worst': 2, 'music1': 2, 'music0': 1, 'music2': 1, 'filler8': 1})\n",
      "Counter({'music1': 2, 'music2': 2, 'terrible': 1, 'bad': 1, 'filler9': 1})\n",
      "Counter({'music0': 3, 'bad': 2, 'music1': 1, 'filler1': 1})\n",
      "Counter({'music1': 3, 'fantastic': 1, 'excellent': 1, 'music0': 1, 'filler3': 1})\n",
      "Counter({'music0': 2, 'good': 1, 'great': 1, 'music2': 1, 'music1': 1, 'filler6': 1})\n",
      "Counter({'plot0': 2, 'plot1': 2, 'great': 1, 'fantastic': 1, 'filler4': 1})\n"
     ]
    }
   ],
   "source": [
    "examples = generateClusteringExamples(10, 3, 10)\n",
    "K = 6\n",
    "maxIters = 10\n",
    "def get_euclidean_distance(v1, v2):\n",
    "    res = 0\n",
    "    keys = list(set(list(v1.keys()) + list(v2.keys())))\n",
    "    for key in keys:\n",
    "        res += (v1.get(key, 0) - v2.get(key, 0))**2\n",
    "    res = math.sqrt(res)\n",
    "    return res\n",
    "    \n",
    "centers = random.sample(examples, K)\n",
    "pre_loss = 0\n",
    "    #for _ in range(maxIters):\n",
    "    # 벡터를 가까운 center에 할당, L2 loss 계산\n",
    "assignments = []\n",
    "loss = 0\n",
    "for example in examples:\n",
    "    distances = [get_euclidean_distance(example, center) for center in centers]\n",
    "    min_index = distances.index(min(distances))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b4caafce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x1 = {0:0, 1:0}\n",
    "x2 = {0:0, 1:1}\n",
    "x3 = {0:0, 1:2}\n",
    "x4 = {0:0, 1:3}\n",
    "x5 = {0:0, 1:4}\n",
    "x6 = {0:0, 1:5}\n",
    "for k in x1.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08065186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
